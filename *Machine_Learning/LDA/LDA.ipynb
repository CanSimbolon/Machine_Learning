{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# LDA \n",
    "\n",
    "Reuters Data: A collection of documents that appeared on Reuters newswire in 1987. The documents were assembled and indexed with categories.\n",
    "\n",
    "Source: \n",
    "- https://pythonhosted.org/lda/\n",
    "- https://pypi.python.org/pypi/lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Getting-started\" data-toc-modified-id=\"Getting-started-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Getting started</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Modeling</a></span></li><li><span><a href=\"#Topic-Analysis\" data-toc-modified-id=\"Topic-Analysis-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Topic Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Putting-it-together\" data-toc-modified-id=\"Putting-it-together-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Putting it together</a></span></li></ul></li><li><span><a href=\"#All-Together\" data-toc-modified-id=\"All-Together-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>All Together</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# install lda package \n",
    "# ! pip install lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np\n",
    "import lda\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395, 4258)\n",
      "<class 'numpy.ndarray'>\n",
      "84010\n"
     ]
    }
   ],
   "source": [
    "X = lda.datasets.load_reuters()\n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "print(X.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('church', 'pope', 'years', 'people', 'mother', 'last', 'told', 'first', 'world', 'year')\n",
      "4258\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "print(vocab[:10])\n",
    "print(len(vocab))\n",
    "print(type(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0 UK: Prince Charles spearheads British royal revolution. LONDON 1996-08-20',\n",
      " '1 GERMANY: Historic Dresden church rising from WW2 ashes. DRESDEN, Germany '\n",
      " '1996-08-21')\n",
      "395\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "titles = lda.datasets.load_reuters_titles()\n",
    "pprint(titles[:2])\n",
    "print(len(titles))\n",
    "print(type(titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 395\n",
      "INFO:lda:vocab_size: 4258\n",
      "INFO:lda:n_words: 84010\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 1500\n",
      "INFO:lda:<0> log likelihood: -1051748\n",
      "INFO:lda:<10> log likelihood: -719800\n",
      "INFO:lda:<20> log likelihood: -699115\n",
      "INFO:lda:<30> log likelihood: -689370\n",
      "INFO:lda:<40> log likelihood: -684918\n",
      "INFO:lda:<50> log likelihood: -681322\n",
      "INFO:lda:<60> log likelihood: -678979\n",
      "INFO:lda:<70> log likelihood: -676598\n",
      "INFO:lda:<80> log likelihood: -675383\n",
      "INFO:lda:<90> log likelihood: -673316\n",
      "INFO:lda:<100> log likelihood: -672761\n",
      "INFO:lda:<110> log likelihood: -671320\n",
      "INFO:lda:<120> log likelihood: -669744\n",
      "INFO:lda:<130> log likelihood: -669292\n",
      "INFO:lda:<140> log likelihood: -667940\n",
      "INFO:lda:<150> log likelihood: -668038\n",
      "INFO:lda:<160> log likelihood: -667429\n",
      "INFO:lda:<170> log likelihood: -666475\n",
      "INFO:lda:<180> log likelihood: -665562\n",
      "INFO:lda:<190> log likelihood: -664920\n",
      "INFO:lda:<200> log likelihood: -664979\n",
      "INFO:lda:<210> log likelihood: -664722\n",
      "INFO:lda:<220> log likelihood: -664459\n",
      "INFO:lda:<230> log likelihood: -664360\n",
      "INFO:lda:<240> log likelihood: -663600\n",
      "INFO:lda:<250> log likelihood: -664164\n",
      "INFO:lda:<260> log likelihood: -663826\n",
      "INFO:lda:<270> log likelihood: -663458\n",
      "INFO:lda:<280> log likelihood: -663393\n",
      "INFO:lda:<290> log likelihood: -662904\n",
      "INFO:lda:<300> log likelihood: -662294\n",
      "INFO:lda:<310> log likelihood: -662031\n",
      "INFO:lda:<320> log likelihood: -662430\n",
      "INFO:lda:<330> log likelihood: -661601\n",
      "INFO:lda:<340> log likelihood: -662108\n",
      "INFO:lda:<350> log likelihood: -662152\n",
      "INFO:lda:<360> log likelihood: -661899\n",
      "INFO:lda:<370> log likelihood: -661012\n",
      "INFO:lda:<380> log likelihood: -661278\n",
      "INFO:lda:<390> log likelihood: -661085\n",
      "INFO:lda:<400> log likelihood: -660418\n",
      "INFO:lda:<410> log likelihood: -660510\n",
      "INFO:lda:<420> log likelihood: -660343\n",
      "INFO:lda:<430> log likelihood: -659789\n",
      "INFO:lda:<440> log likelihood: -659336\n",
      "INFO:lda:<450> log likelihood: -659039\n",
      "INFO:lda:<460> log likelihood: -659329\n",
      "INFO:lda:<470> log likelihood: -658707\n",
      "INFO:lda:<480> log likelihood: -658879\n",
      "INFO:lda:<490> log likelihood: -658819\n",
      "INFO:lda:<500> log likelihood: -658407\n",
      "INFO:lda:<510> log likelihood: -658651\n",
      "INFO:lda:<520> log likelihood: -658111\n",
      "INFO:lda:<530> log likelihood: -658018\n",
      "INFO:lda:<540> log likelihood: -658111\n",
      "INFO:lda:<550> log likelihood: -657925\n",
      "INFO:lda:<560> log likelihood: -657860\n",
      "INFO:lda:<570> log likelihood: -657494\n",
      "INFO:lda:<580> log likelihood: -657723\n",
      "INFO:lda:<590> log likelihood: -657591\n",
      "INFO:lda:<600> log likelihood: -657557\n",
      "INFO:lda:<610> log likelihood: -657505\n",
      "INFO:lda:<620> log likelihood: -657730\n",
      "INFO:lda:<630> log likelihood: -657304\n",
      "INFO:lda:<640> log likelihood: -657208\n",
      "INFO:lda:<650> log likelihood: -657518\n",
      "INFO:lda:<660> log likelihood: -657541\n",
      "INFO:lda:<670> log likelihood: -657381\n",
      "INFO:lda:<680> log likelihood: -657575\n",
      "INFO:lda:<690> log likelihood: -656985\n",
      "INFO:lda:<700> log likelihood: -656815\n",
      "INFO:lda:<710> log likelihood: -656930\n",
      "INFO:lda:<720> log likelihood: -656538\n",
      "INFO:lda:<730> log likelihood: -656291\n",
      "INFO:lda:<740> log likelihood: -656417\n",
      "INFO:lda:<750> log likelihood: -656747\n",
      "INFO:lda:<760> log likelihood: -656600\n",
      "INFO:lda:<770> log likelihood: -656269\n",
      "INFO:lda:<780> log likelihood: -656311\n",
      "INFO:lda:<790> log likelihood: -656069\n",
      "INFO:lda:<800> log likelihood: -656228\n",
      "INFO:lda:<810> log likelihood: -656178\n",
      "INFO:lda:<820> log likelihood: -655694\n",
      "INFO:lda:<830> log likelihood: -655997\n",
      "INFO:lda:<840> log likelihood: -656224\n",
      "INFO:lda:<850> log likelihood: -656197\n",
      "INFO:lda:<860> log likelihood: -655889\n",
      "INFO:lda:<870> log likelihood: -656180\n",
      "INFO:lda:<880> log likelihood: -656997\n",
      "INFO:lda:<890> log likelihood: -655989\n",
      "INFO:lda:<900> log likelihood: -655615\n",
      "INFO:lda:<910> log likelihood: -655584\n",
      "INFO:lda:<920> log likelihood: -656602\n",
      "INFO:lda:<930> log likelihood: -656083\n",
      "INFO:lda:<940> log likelihood: -656294\n",
      "INFO:lda:<950> log likelihood: -656257\n",
      "INFO:lda:<960> log likelihood: -656243\n",
      "INFO:lda:<970> log likelihood: -656028\n",
      "INFO:lda:<980> log likelihood: -655603\n",
      "INFO:lda:<990> log likelihood: -656012\n",
      "INFO:lda:<1000> log likelihood: -655849\n",
      "INFO:lda:<1010> log likelihood: -655376\n",
      "INFO:lda:<1020> log likelihood: -655417\n",
      "INFO:lda:<1030> log likelihood: -655856\n",
      "INFO:lda:<1040> log likelihood: -655197\n",
      "INFO:lda:<1050> log likelihood: -655938\n",
      "INFO:lda:<1060> log likelihood: -655529\n",
      "INFO:lda:<1070> log likelihood: -655092\n",
      "INFO:lda:<1080> log likelihood: -655119\n",
      "INFO:lda:<1090> log likelihood: -656215\n",
      "INFO:lda:<1100> log likelihood: -655602\n",
      "INFO:lda:<1110> log likelihood: -655296\n",
      "INFO:lda:<1120> log likelihood: -655547\n",
      "INFO:lda:<1130> log likelihood: -655580\n",
      "INFO:lda:<1140> log likelihood: -655604\n",
      "INFO:lda:<1150> log likelihood: -655168\n",
      "INFO:lda:<1160> log likelihood: -655281\n",
      "INFO:lda:<1170> log likelihood: -655409\n",
      "INFO:lda:<1180> log likelihood: -655517\n",
      "INFO:lda:<1190> log likelihood: -654922\n",
      "INFO:lda:<1200> log likelihood: -655304\n",
      "INFO:lda:<1210> log likelihood: -655852\n",
      "INFO:lda:<1220> log likelihood: -655184\n",
      "INFO:lda:<1230> log likelihood: -655650\n",
      "INFO:lda:<1240> log likelihood: -655606\n",
      "INFO:lda:<1250> log likelihood: -656086\n",
      "INFO:lda:<1260> log likelihood: -655698\n",
      "INFO:lda:<1270> log likelihood: -655351\n",
      "INFO:lda:<1280> log likelihood: -655686\n",
      "INFO:lda:<1290> log likelihood: -654801\n",
      "INFO:lda:<1300> log likelihood: -654973\n",
      "INFO:lda:<1310> log likelihood: -655186\n",
      "INFO:lda:<1320> log likelihood: -655128\n",
      "INFO:lda:<1330> log likelihood: -655365\n",
      "INFO:lda:<1340> log likelihood: -655338\n",
      "INFO:lda:<1350> log likelihood: -655219\n",
      "INFO:lda:<1360> log likelihood: -655115\n",
      "INFO:lda:<1370> log likelihood: -654930\n",
      "INFO:lda:<1380> log likelihood: -655209\n",
      "INFO:lda:<1390> log likelihood: -654940\n",
      "INFO:lda:<1400> log likelihood: -655055\n",
      "INFO:lda:<1410> log likelihood: -655286\n",
      "INFO:lda:<1420> log likelihood: -655316\n",
      "INFO:lda:<1430> log likelihood: -655257\n",
      "INFO:lda:<1440> log likelihood: -654964\n",
      "INFO:lda:<1450> log likelihood: -654884\n",
      "INFO:lda:<1460> log likelihood: -655493\n",
      "INFO:lda:<1470> log likelihood: -655415\n",
      "INFO:lda:<1480> log likelihood: -655192\n",
      "INFO:lda:<1490> log likelihood: -655728\n",
      "INFO:lda:<1499> log likelihood: -655858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x10ee0fbe0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
    "model.fit(X)  # model.fit_transform(X) is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.62505347e-06   3.62505347e-06   3.62505347e-06 ...,   3.62505347e-06\n",
      "   3.62505347e-06   3.62505347e-06]\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "print(topic_word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: british churchill sale million major letters west\n",
      "Topic 1: church government political country state people party\n",
      "Topic 2: elvis king fans presley life concert young\n",
      "Topic 3: yeltsin russian russia president kremlin moscow michael\n",
      "Topic 4: pope vatican paul john surgery hospital pontiff\n",
      "Topic 5: family funeral police miami versace cunanan city\n",
      "Topic 6: simpson former years court president wife south\n",
      "Topic 7: order mother successor election nuns church nirmala\n",
      "Topic 8: charles prince diana royal king queen parker\n",
      "Topic 9: film french france against bardot paris poster\n",
      "Topic 10: germany german war nazi letter christian book\n",
      "Topic 11: east peace prize award timor quebec belo\n",
      "Topic 12: n't life show told very love television\n",
      "Topic 13: years year time last church world people\n",
      "Topic 14: mother teresa heart calcutta charity nun hospital\n",
      "Topic 15: city salonika capital buddhist cultural vietnam byzantine\n",
      "Topic 16: music tour opera singer israel people film\n",
      "Topic 17: church catholic bernardin cardinal bishop wright death\n",
      "Topic 18: harriman clinton u.s ambassador paris president churchill\n",
      "Topic 19: city museum art exhibition century million churches\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.34782609e-04   3.52173913e-02   4.34782609e-04   9.13043478e-03\n",
      "   4.78260870e-03   4.34782609e-04   9.13043478e-03   3.08695652e-02\n",
      "   5.04782609e-01   4.78260870e-03   4.34782609e-04   4.34782609e-04\n",
      "   3.08695652e-02   2.17826087e-01   4.34782609e-04   4.34782609e-04\n",
      "   4.34782609e-04   3.95652174e-02   4.34782609e-04   1.09130435e-01]\n",
      "(395, 20)\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "print(doc_topic[0])\n",
    "print(doc_topic.shape)\n",
    "# each row represents document, \n",
    "# and provides probabilities for each topic in the given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows that for document 0, topic 8 has the highest probability\n",
    "doc_topic[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 13, 14, 8, 14, 14, 14, 14, 14, 8]\n"
     ]
    }
   ],
   "source": [
    "# get the topic for each document \n",
    "doc_topics = []\n",
    "for i in doc_topic: \n",
    "    doc_topics.append(i.argmax())\n",
    "\n",
    "print(doc_topics[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    56\n",
       "8     36\n",
       "4     31\n",
       "1     29\n",
       "3     23\n",
       "5     22\n",
       "18    21\n",
       "6     20\n",
       "17    18\n",
       "10    18\n",
       "16    17\n",
       "11    17\n",
       "14    16\n",
       "0     15\n",
       "9     13\n",
       "19    11\n",
       "7      9\n",
       "12     9\n",
       "2      8\n",
       "15     6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows that topic 13 is the most frequent\n",
    "pd.Series(doc_topics).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 8, 4, 1, 3, 5, 18, 6, 17, 10]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 10 most frequent in order \n",
    "top_topics = list(pd.Series(doc_topics).value_counts()[:10].index)\n",
    "top_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'british churchill sale million major letters west britain john'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topic_n_words = []\n",
    "n_top_words = 10\n",
    "topic_n_words = {}\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    # (topic, words)\n",
    "    #topic_n_words.append((i,topic_words))\n",
    "    topic_n_words[i] = ' '.join(topic_words)\n",
    "    \n",
    "topic_n_words[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['city', 'museum', 'art', 'exhibition', 'century', 'million',\n",
       "       'churches', 'set', 'used'], \n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Frequent Topics\n",
      "Topic 13: years year time last church world people say during\n",
      "Topic 8: charles prince diana royal king queen parker bowles camilla\n",
      "Topic 4: pope vatican paul john surgery hospital pontiff rome mass\n",
      "Topic 1: church government political country state people party against first\n",
      "Topic 3: yeltsin russian russia president kremlin moscow michael operation orthodox\n",
      "Topic 5: family funeral police miami versace cunanan city service home\n",
      "Topic 18: harriman clinton u.s ambassador paris president churchill france american\n",
      "Topic 6: simpson former years court president wife south church york\n",
      "Topic 17: church catholic bernardin cardinal bishop wright death cancer chicago\n",
      "Topic 10: germany german war nazi letter christian book jews scientology\n"
     ]
    }
   ],
   "source": [
    "# get top 10 topics and its words \n",
    "print('10 Most Frequent Topics')\n",
    "for i in top_topics: \n",
    "    print('Topic %s: %s' % (i, str(topic_n_words[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 UK: Prince Charles spearheads British royal revolution. LONDON 1996-08-20 (top topic: 8)\n",
      "1 GERMANY: Historic Dresden church rising from WW2 ashes. DRESDEN, Germany 1996-08-21 (top topic: 13)\n",
      "2 INDIA: Mother Teresa's condition said still unstable. CALCUTTA 1996-08-23 (top topic: 14)\n",
      "3 UK: Palace warns British weekly over Charles pictures. LONDON 1996-08-25 (top topic: 8)\n",
      "4 INDIA: Mother Teresa, slightly stronger, blesses nuns. CALCUTTA 1996-08-25 (top topic: 14)\n",
      "5 INDIA: Mother Teresa's condition unchanged, thousands pray. CALCUTTA 1996-08-25 (top topic: 14)\n",
      "6 INDIA: Mother Teresa shows signs of strength, blesses nuns. CALCUTTA 1996-08-26 (top topic: 14)\n",
      "7 INDIA: Mother Teresa's condition improves, many pray. CALCUTTA, India 1996-08-25 (top topic: 14)\n",
      "8 INDIA: Mother Teresa improves, nuns pray for \"miracle\". CALCUTTA 1996-08-26 (top topic: 14)\n",
      "9 UK: Charles under fire over prospect of Queen Camilla. LONDON 1996-08-26 (top topic: 8)\n"
     ]
    }
   ],
   "source": [
    "# displaying titles with top topics \n",
    "for i in range(10):\n",
    "    print(\"{} (top topic: {})\".format(titles[i], doc_topic[i].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Putting it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Frequent Topics\n",
      "Topic 13: years year time last church world people say during\n",
      "Topic 8: charles prince diana royal king queen parker bowles camilla\n",
      "Topic 4: pope vatican paul john surgery hospital pontiff rome mass\n",
      "Topic 1: church government political country state people party against first\n",
      "Topic 3: yeltsin russian russia president kremlin moscow michael operation orthodox\n",
      "Topic 5: family funeral police miami versace cunanan city service home\n",
      "Topic 18: harriman clinton u.s ambassador paris president churchill france american\n",
      "Topic 6: simpson former years court president wife south church york\n",
      "Topic 17: church catholic bernardin cardinal bishop wright death cancer chicago\n",
      "Topic 10: germany german war nazi letter christian book jews scientology\n"
     ]
    }
   ],
   "source": [
    "topic_word = model.topic_word_\n",
    "doc_topic = model.doc_topic_\n",
    "\n",
    "# get the top 10 most frequent in order \n",
    "top_topics = list(pd.Series(doc_topics).value_counts()[:10].index)\n",
    "\n",
    "# get the topic for each document \n",
    "doc_topics = []\n",
    "for i in doc_topic: \n",
    "    doc_topics.append(i.argmax())\n",
    "\n",
    "n_top_words = 10\n",
    "topic_n_words = {}\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    # (topic, words)\n",
    "    topic_n_words[i] = ' '.join(topic_words)\n",
    "    \n",
    "# get top 10 topics and its words \n",
    "print('10 Most Frequent Topics')\n",
    "for i in top_topics: \n",
    "    print('Topic %s: %s' % (i, str(topic_n_words[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## All Together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 395\n",
      "INFO:lda:vocab_size: 4258\n",
      "INFO:lda:n_words: 84010\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 1500\n",
      "INFO:lda:<0> log likelihood: -1051748\n",
      "INFO:lda:<10> log likelihood: -719800\n",
      "INFO:lda:<20> log likelihood: -699115\n",
      "INFO:lda:<30> log likelihood: -689370\n",
      "INFO:lda:<40> log likelihood: -684918\n",
      "INFO:lda:<50> log likelihood: -681322\n",
      "INFO:lda:<60> log likelihood: -678979\n",
      "INFO:lda:<70> log likelihood: -676598\n",
      "INFO:lda:<80> log likelihood: -675383\n",
      "INFO:lda:<90> log likelihood: -673316\n",
      "INFO:lda:<100> log likelihood: -672761\n",
      "INFO:lda:<110> log likelihood: -671320\n",
      "INFO:lda:<120> log likelihood: -669744\n",
      "INFO:lda:<130> log likelihood: -669292\n",
      "INFO:lda:<140> log likelihood: -667940\n",
      "INFO:lda:<150> log likelihood: -668038\n",
      "INFO:lda:<160> log likelihood: -667429\n",
      "INFO:lda:<170> log likelihood: -666475\n",
      "INFO:lda:<180> log likelihood: -665562\n",
      "INFO:lda:<190> log likelihood: -664920\n",
      "INFO:lda:<200> log likelihood: -664979\n",
      "INFO:lda:<210> log likelihood: -664722\n",
      "INFO:lda:<220> log likelihood: -664459\n",
      "INFO:lda:<230> log likelihood: -664360\n",
      "INFO:lda:<240> log likelihood: -663600\n",
      "INFO:lda:<250> log likelihood: -664164\n",
      "INFO:lda:<260> log likelihood: -663826\n",
      "INFO:lda:<270> log likelihood: -663458\n",
      "INFO:lda:<280> log likelihood: -663393\n",
      "INFO:lda:<290> log likelihood: -662904\n",
      "INFO:lda:<300> log likelihood: -662294\n",
      "INFO:lda:<310> log likelihood: -662031\n",
      "INFO:lda:<320> log likelihood: -662430\n",
      "INFO:lda:<330> log likelihood: -661601\n",
      "INFO:lda:<340> log likelihood: -662108\n",
      "INFO:lda:<350> log likelihood: -662152\n",
      "INFO:lda:<360> log likelihood: -661899\n",
      "INFO:lda:<370> log likelihood: -661012\n",
      "INFO:lda:<380> log likelihood: -661278\n",
      "INFO:lda:<390> log likelihood: -661085\n",
      "INFO:lda:<400> log likelihood: -660418\n",
      "INFO:lda:<410> log likelihood: -660510\n",
      "INFO:lda:<420> log likelihood: -660343\n",
      "INFO:lda:<430> log likelihood: -659789\n",
      "INFO:lda:<440> log likelihood: -659336\n",
      "INFO:lda:<450> log likelihood: -659039\n",
      "INFO:lda:<460> log likelihood: -659329\n",
      "INFO:lda:<470> log likelihood: -658707\n",
      "INFO:lda:<480> log likelihood: -658879\n",
      "INFO:lda:<490> log likelihood: -658819\n",
      "INFO:lda:<500> log likelihood: -658407\n",
      "INFO:lda:<510> log likelihood: -658651\n",
      "INFO:lda:<520> log likelihood: -658111\n",
      "INFO:lda:<530> log likelihood: -658018\n",
      "INFO:lda:<540> log likelihood: -658111\n",
      "INFO:lda:<550> log likelihood: -657925\n",
      "INFO:lda:<560> log likelihood: -657860\n",
      "INFO:lda:<570> log likelihood: -657494\n",
      "INFO:lda:<580> log likelihood: -657723\n",
      "INFO:lda:<590> log likelihood: -657591\n",
      "INFO:lda:<600> log likelihood: -657557\n",
      "INFO:lda:<610> log likelihood: -657505\n",
      "INFO:lda:<620> log likelihood: -657730\n",
      "INFO:lda:<630> log likelihood: -657304\n",
      "INFO:lda:<640> log likelihood: -657208\n",
      "INFO:lda:<650> log likelihood: -657518\n",
      "INFO:lda:<660> log likelihood: -657541\n",
      "INFO:lda:<670> log likelihood: -657381\n",
      "INFO:lda:<680> log likelihood: -657575\n",
      "INFO:lda:<690> log likelihood: -656985\n",
      "INFO:lda:<700> log likelihood: -656815\n",
      "INFO:lda:<710> log likelihood: -656930\n",
      "INFO:lda:<720> log likelihood: -656538\n",
      "INFO:lda:<730> log likelihood: -656291\n",
      "INFO:lda:<740> log likelihood: -656417\n",
      "INFO:lda:<750> log likelihood: -656747\n",
      "INFO:lda:<760> log likelihood: -656600\n",
      "INFO:lda:<770> log likelihood: -656269\n",
      "INFO:lda:<780> log likelihood: -656311\n",
      "INFO:lda:<790> log likelihood: -656069\n",
      "INFO:lda:<800> log likelihood: -656228\n",
      "INFO:lda:<810> log likelihood: -656178\n",
      "INFO:lda:<820> log likelihood: -655694\n",
      "INFO:lda:<830> log likelihood: -655997\n",
      "INFO:lda:<840> log likelihood: -656224\n",
      "INFO:lda:<850> log likelihood: -656197\n",
      "INFO:lda:<860> log likelihood: -655889\n",
      "INFO:lda:<870> log likelihood: -656180\n",
      "INFO:lda:<880> log likelihood: -656997\n",
      "INFO:lda:<890> log likelihood: -655989\n",
      "INFO:lda:<900> log likelihood: -655615\n",
      "INFO:lda:<910> log likelihood: -655584\n",
      "INFO:lda:<920> log likelihood: -656602\n",
      "INFO:lda:<930> log likelihood: -656083\n",
      "INFO:lda:<940> log likelihood: -656294\n",
      "INFO:lda:<950> log likelihood: -656257\n",
      "INFO:lda:<960> log likelihood: -656243\n",
      "INFO:lda:<970> log likelihood: -656028\n",
      "INFO:lda:<980> log likelihood: -655603\n",
      "INFO:lda:<990> log likelihood: -656012\n",
      "INFO:lda:<1000> log likelihood: -655849\n",
      "INFO:lda:<1010> log likelihood: -655376\n",
      "INFO:lda:<1020> log likelihood: -655417\n",
      "INFO:lda:<1030> log likelihood: -655856\n",
      "INFO:lda:<1040> log likelihood: -655197\n",
      "INFO:lda:<1050> log likelihood: -655938\n",
      "INFO:lda:<1060> log likelihood: -655529\n",
      "INFO:lda:<1070> log likelihood: -655092\n",
      "INFO:lda:<1080> log likelihood: -655119\n",
      "INFO:lda:<1090> log likelihood: -656215\n",
      "INFO:lda:<1100> log likelihood: -655602\n",
      "INFO:lda:<1110> log likelihood: -655296\n",
      "INFO:lda:<1120> log likelihood: -655547\n",
      "INFO:lda:<1130> log likelihood: -655580\n",
      "INFO:lda:<1140> log likelihood: -655604\n",
      "INFO:lda:<1150> log likelihood: -655168\n",
      "INFO:lda:<1160> log likelihood: -655281\n",
      "INFO:lda:<1170> log likelihood: -655409\n",
      "INFO:lda:<1180> log likelihood: -655517\n",
      "INFO:lda:<1190> log likelihood: -654922\n",
      "INFO:lda:<1200> log likelihood: -655304\n",
      "INFO:lda:<1210> log likelihood: -655852\n",
      "INFO:lda:<1220> log likelihood: -655184\n",
      "INFO:lda:<1230> log likelihood: -655650\n",
      "INFO:lda:<1240> log likelihood: -655606\n",
      "INFO:lda:<1250> log likelihood: -656086\n",
      "INFO:lda:<1260> log likelihood: -655698\n",
      "INFO:lda:<1270> log likelihood: -655351\n",
      "INFO:lda:<1280> log likelihood: -655686\n",
      "INFO:lda:<1290> log likelihood: -654801\n",
      "INFO:lda:<1300> log likelihood: -654973\n",
      "INFO:lda:<1310> log likelihood: -655186\n",
      "INFO:lda:<1320> log likelihood: -655128\n",
      "INFO:lda:<1330> log likelihood: -655365\n",
      "INFO:lda:<1340> log likelihood: -655338\n",
      "INFO:lda:<1350> log likelihood: -655219\n",
      "INFO:lda:<1360> log likelihood: -655115\n",
      "INFO:lda:<1370> log likelihood: -654930\n",
      "INFO:lda:<1380> log likelihood: -655209\n",
      "INFO:lda:<1390> log likelihood: -654940\n",
      "INFO:lda:<1400> log likelihood: -655055\n",
      "INFO:lda:<1410> log likelihood: -655286\n",
      "INFO:lda:<1420> log likelihood: -655316\n",
      "INFO:lda:<1430> log likelihood: -655257\n",
      "INFO:lda:<1440> log likelihood: -654964\n",
      "INFO:lda:<1450> log likelihood: -654884\n",
      "INFO:lda:<1460> log likelihood: -655493\n",
      "INFO:lda:<1470> log likelihood: -655415\n",
      "INFO:lda:<1480> log likelihood: -655192\n",
      "INFO:lda:<1490> log likelihood: -655728\n",
      "INFO:lda:<1499> log likelihood: -655858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: british churchill sale million major letters west\n",
      "Topic 1: church government political country state people party\n",
      "Topic 2: elvis king fans presley life concert young\n",
      "Topic 3: yeltsin russian russia president kremlin moscow michael\n",
      "Topic 4: pope vatican paul john surgery hospital pontiff\n",
      "Topic 5: family funeral police miami versace cunanan city\n",
      "Topic 6: simpson former years court president wife south\n",
      "Topic 7: order mother successor election nuns church nirmala\n",
      "Topic 8: charles prince diana royal king queen parker\n",
      "Topic 9: film french france against bardot paris poster\n",
      "Topic 10: germany german war nazi letter christian book\n",
      "Topic 11: east peace prize award timor quebec belo\n",
      "Topic 12: n't life show told very love television\n",
      "Topic 13: years year time last church world people\n",
      "Topic 14: mother teresa heart calcutta charity nun hospital\n",
      "Topic 15: city salonika capital buddhist cultural vietnam byzantine\n",
      "Topic 16: music tour opera singer israel people film\n",
      "Topic 17: church catholic bernardin cardinal bishop wright death\n",
      "Topic 18: harriman clinton u.s ambassador paris president churchill\n",
      "Topic 19: city museum art exhibition century million churches\n"
     ]
    }
   ],
   "source": [
    "# import packages \n",
    "import numpy as np\n",
    "import lda\n",
    "from pprint import pprint\n",
    "\n",
    "X = lda.datasets.load_reuters()\n",
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "titles = lda.datasets.load_reuters_titles()\n",
    "\n",
    "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
    "model.fit(X)  # model.fit_transform(X) is also available\n",
    "\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LDA in module lda.lda:\n",
      "\n",
      "class LDA(builtins.object)\n",
      " |  Latent Dirichlet allocation using collapsed Gibbs sampling\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_topics : int\n",
      " |      Number of topics\n",
      " |  \n",
      " |  n_iter : int, default 2000\n",
      " |      Number of sampling iterations\n",
      " |  \n",
      " |  alpha : float, default 0.1\n",
      " |      Dirichlet parameter for distribution over topics\n",
      " |  \n",
      " |  eta : float, default 0.01\n",
      " |      Dirichlet parameter for distribution over words\n",
      " |  \n",
      " |  random_state : int or RandomState, optional\n",
      " |      The generator used for the initial topics.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  `components_` : array, shape = [n_topics, n_features]\n",
      " |      Point estimate of the topic-word distributions (Phi in literature)\n",
      " |  `topic_word_` :\n",
      " |      Alias for `components_`\n",
      " |  `nzw_` : array, shape = [n_topics, n_features]\n",
      " |      Matrix of counts recording topic-word assignments in final iteration.\n",
      " |  `ndz_` : array, shape = [n_samples, n_topics]\n",
      " |      Matrix of counts recording document-topic assignments in final iteration.\n",
      " |  `doc_topic_` : array, shape = [n_samples, n_features]\n",
      " |      Point estimate of the document-topic distributions (Theta in literature)\n",
      " |  `nz_` : array, shape = [n_topics]\n",
      " |      Array of topic assignment counts in final iteration.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy\n",
      " |  >>> X = numpy.array([[1,1], [2, 1], [3, 1], [4, 1], [5, 8], [6, 1]])\n",
      " |  >>> import lda\n",
      " |  >>> model = lda.LDA(n_topics=2, random_state=0, n_iter=100)\n",
      " |  >>> model.fit(X) #doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
      " |  LDA(alpha=...\n",
      " |  >>> model.components_\n",
      " |  array([[ 0.85714286,  0.14285714],\n",
      " |         [ 0.45      ,  0.55      ]])\n",
      " |  >>> model.loglikelihood() #doctest: +ELLIPSIS\n",
      " |  -40.395...\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Blei, David M., Andrew Y. Ng, and Michael I. Jordan. \"Latent Dirichlet\n",
      " |  Allocation.\" Journal of Machine Learning Research 3 (2003): 993–1022.\n",
      " |  \n",
      " |  Griffiths, Thomas L., and Mark Steyvers. \"Finding Scientific Topics.\"\n",
      " |  Proceedings of the National Academy of Sciences 101 (2004): 5228–5235.\n",
      " |  doi:10.1073/pnas.0307752101.\n",
      " |  \n",
      " |  Wallach, Hanna, David Mimno, and Andrew McCallum. \"Rethinking LDA: Why\n",
      " |  Priors Matter.\" In Advances in Neural Information Processing Systems 22,\n",
      " |  edited by Y.  Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A.\n",
      " |  Culotta, 1973–1981, 2009.\n",
      " |  \n",
      " |  Buntine, Wray. \"Estimating Likelihoods for Topic Models.\" In Advances in\n",
      " |  Machine Learning, First Asian Conference on Machine Learning (2009): 51–64.\n",
      " |  doi:10.1007/978-3-642-05224-8_6.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_topics, n_iter=2000, alpha=0.1, eta=0.01, random_state=None, refresh=10)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Fit the model with X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X: array-like, shape (n_samples, n_features)\n",
      " |          Training data, where n_samples in the number of samples\n",
      " |          and n_features is the number of features. Sparse matrix allowed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns the instance itself.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None)\n",
      " |      Apply dimensionality reduction on X\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          New data, where n_samples in the number of samples\n",
      " |          and n_features is the number of features. Sparse matrix allowed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      doc_topic : array-like, shape (n_samples, n_topics)\n",
      " |          Point estimate of the document-topic distributions\n",
      " |  \n",
      " |  loglikelihood(self)\n",
      " |      Calculate complete log likelihood, log p(w,z)\n",
      " |      \n",
      " |      Formula used is log p(w,z) = log p(w|z) + log p(z)\n",
      " |  \n",
      " |  transform(self, X, max_iter=20, tol=1e-16)\n",
      " |      Transform the data X according to previously fitted model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          New data, where n_samples in the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      max_iter : int, optional\n",
      " |          Maximum number of iterations in iterated-pseudocount estimation.\n",
      " |      tol: double, optional\n",
      " |          Tolerance value used in stopping condition.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      doc_topic : array-like, shape (n_samples, n_topics)\n",
      " |          Point estimate of the document-topic distributions\n",
      " |      \n",
      " |      Note\n",
      " |      ----\n",
      " |      This uses the \"iterated pseudo-counts\" approach described\n",
      " |      in Wallach et al. (2009) and discussed in Buntine (2009).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lda.LDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "687px",
    "left": "0px",
    "right": "1334px",
    "top": "106px",
    "width": "106px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
