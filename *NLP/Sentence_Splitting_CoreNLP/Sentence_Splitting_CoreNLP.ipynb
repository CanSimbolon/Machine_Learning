{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Splitting\n",
    "\n",
    "Tutorial for splitting setences using nltk and Stanford's CoreNLP. I also showed example of regex-ing timestamps from the document. \n",
    "First download CoreNLP from: https://stanfordnlp.github.io/CoreNLP/. \n",
    "Unzip the file and cd into that folder from the terminal and run: \n",
    "\n",
    "- java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000 \n",
    "\n",
    "Which starts up a CoreNLP server on your local machine. You can check by entering http://localhost:9000 on your browser. \n",
    "\n",
    "To use python wrapper for CoreNLP, run on your terminal: \n",
    "- pip install pycorenlp \n",
    "\n",
    "credit: http://titipata.github.io/2016/11/09/sentence-split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from os import system \n",
    "import re \n",
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# python wrapper for coreNLP \n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is sample text for setence splitting. I don't know what else to say. It is 12:20 pm right now. \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'input.txt'\n",
    "\n",
    "# read text \n",
    "f = open(path,'r')\n",
    "data = f.read()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Method \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This', 'is', 'sample', 'text', 'for', 'setence', 'splitting', '.'],\n",
       " ['I', 'do', \"n't\", 'know', 'what', 'else', 'to', 'say', '.'],\n",
       " ['It', 'is', '12:20', 'pm', 'right', 'now', '.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def sent_split(documents):\n",
    "    words = [word_tokenize(sent) for sent in sent_tokenize(documents)]\n",
    "    return words\n",
    "\n",
    "sent_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoreNLP Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This', 'is', 'sample', 'text', 'for', 'setence', 'splitting', '.'],\n",
       " ['I', 'do', \"n't\", 'know', 'what', 'else', 'to', 'say', '.'],\n",
       " ['It', 'is', '12:20', 'pm', 'right', 'now', '.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_split(text, properties):\n",
    "    # split sentences \n",
    "    annotated = nlp.annotate(text, properties)\n",
    "    sentence_split = list()\n",
    "    for sentence in annotated['sentences']:\n",
    "        s = [t['word'] for t in sentence['tokens']]\n",
    "        sentence_split.append(s)\n",
    "    return sentence_split\n",
    "\n",
    "splited = sentence_split(data, properties = {'annotators': 'ssplit','outputFormat': 'json'})\n",
    "splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is sample text for setence splitting .',\n",
       " \"I do n't know what else to say .\",\n",
       " 'It is 12:20 pm right now .']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to put the setences back \n",
    "joined = [' '.join(x) for x in splited]\n",
    "joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Time Stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# patterns \n",
    "week = r'weekened|week|day|weekday|year|month'\n",
    "season = r'\\bspring\\b|\\bsummer\\b|\\bfall\\b|\\bwinter\\b'\n",
    "date = r'[0-9]{1,2}[/\\.-][0-9]{1,2}[/\\.-][0-9]{4}|[0-9]{1,2}[/\\.-][0-9]{1,2}[/\\.-][0-9]{2}'\n",
    "date2 = r'[0-9]{1,2}[/\\.-][0-9]{1,2}[/\\.-][0-9]{4}|[0-9]{1,2}[/\\.-][0-9]{1,2}[/\\.-][0-9]{4}'\n",
    "date3 = r'on [0-9]{1,2}[/\\.-][0-9]{1,2}'\n",
    "dayname = r'monday|tuesday|wednesday|thursday|friday|saturday|sunday'\n",
    "dayname_short = r'\\bmon\\b|\\btue\\b|\\bwed\\b|\\bthurs\\b|\\bfri\\b|\\bsat\\b|\\bsun\\b'\n",
    "month = r'january|february|march|april|\\bmay\\b|june|july|august|september|october|november|december'\n",
    "month_short= r'\\bjan\\b|\\bfeb\\b|\\bmar\\b|\\bapr\\b|\\bmay\\b|\\bjun\\b|\\bjul\\b|\\baug\\b|\\bsep\\b|\\boct\\b|\\bnov\\b|\\bdec\\b'\n",
    "year = r'[0-9]{4}' # 2017 \n",
    "time = r'[0-9]{1,2}:[0-9]{1,2}|[0-9]{1,2}\\s?[ap].?m.?' # 14:00 \n",
    "relative = r'\\bnow\\b|today|yesterday|tomorrow' # know should not be picked up \n",
    "relative2 = '(this|next|last|coming|past|every) ' + '('+ week +'|' +dayname+'|'+dayname_short+'|'+month+'|'+ month_short+'|'+season + ')'\n",
    "\n",
    "# combine all patterns \n",
    "pattern = \"|\".join([relative, relative2, season, date, date2, date3, \n",
    "                    dayname, dayname_short, month, month_short, year,time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<_sre.SRE_Match object; span=(6, 11), match='12:20'>\n",
      "It is 12:20 pm right now .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return sentences with timestamps \n",
    "count = 0\n",
    "for sentence in joined:\n",
    "    \n",
    "    match = re.search(pattern , sentence.lower()) \n",
    "\n",
    "    if match:\n",
    "        print(count)\n",
    "        print(match)    \n",
    "        print(sentence)\n",
    "        print()\n",
    "        count+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the output into file \n",
    "\n",
    "f = open('output.txt','w')\n",
    "count = 0 \n",
    "for sentence in joined:\n",
    "    match = re.search(pattern , sentence.lower()) \n",
    "    if match: \n",
    "        f.writelines(sentence+ '\\n')\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
